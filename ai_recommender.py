#!/usr/bin/env python3
"""
M√≥dulo de Recomenda√ß√µes com IA
Respons√°vel por gerar recomenda√ß√µes inteligentes usando OpenAI
"""

import json
import time
import os
import logging
import pandas as pd
from typing import Optional
from openai import OpenAI

logger = logging.getLogger(__name__)


class AIRecommender:
    """Gerador de recomenda√ß√µes usando IA"""
    
    def __init__(self, openai_model: str = "gpt-4o-mini"):
        """
        Inicializa o recomendador IA
        
        Args:
            openai_model: Nome do modelo OpenAI a usar
        """
        self.openai_model = openai_model
        self.client = None
        self.api_key = os.getenv("OPENAI_API_KEY")
    
    def configure_openai(self, api_key: Optional[str] = None):
        """
        Configura cliente OpenAI
        
        Args:
            api_key: Chave da API OpenAI (opcional, pode usar vari√°vel de ambiente)
        """
        if api_key:
            self.api_key = api_key
        
        if not self.api_key:
            logger.warning(
                "Chave OpenAI n√£o encontrada. Recomenda√ß√µes IA indispon√≠veis.")
            return
        
        try:
            self.client = OpenAI(api_key=self.api_key)
            
            # Testa a conex√£o
            response = self.client.chat.completions.create(
                model=self.openai_model,
                messages=[{"role": "user", "content": "teste"}],
                max_tokens=5
            )
            logger.info("‚úÖ API OpenAI configurada com sucesso!")
            
        except Exception as e:
            logger.error(f"Erro ao configurar OpenAI: {e}")
            self.client = None
    
    def generate_recommendation(self, query: str, results: pd.DataFrame) -> str:
        """
        Usa LLM para analisar resultados e fazer recomenda√ß√µes inteligentes
        
        Args:
            query: Consulta original do usu√°rio
            results: DataFrame com resultados da busca sem√¢ntica
            
        Returns:
            Recomenda√ß√£o textual do LLM
        """
        if not self.client:
            return "‚ùå API OpenAI n√£o configurada. Recomenda√ß√µes IA indispon√≠veis."
        
        logger.info("üß† Analisando resultados com IA...")
        
        # Prepara dados dos resultados para o LLM (s√≥ os top 10)
        top_results = results.head(10)
        
        # Formata resultados para o prompt
        formatted_items = []
        for idx, row in top_results.iterrows():
            item_info = {
                'codigo': row.get('C√≥digo do Item', 'N/A'),
                'descricao': row['Descri√ß√£o do Item'],
                'score': f"{row['Score_Similaridade']:.3f}",
                'classe': row.get('Nome da Classe', 'N/A'),
                'grupo': row.get('Nome do Grupo', 'N/A')
            }
            formatted_items.append(item_info)
        
        # Prompt melhorado
        prompt = f"""Voc√™ √© um especialista em compras p√∫blicas e an√°lise do Catmat (Cat√°logo de Materiais).

SOLICITA√á√ÉO DO USU√ÅRIO: "{query}"

ITENS ENCONTRADOS NA BUSCA SEM√ÇNTICA:
{json.dumps(formatted_items, indent=2, ensure_ascii=False)}

TAREFA:
1. Analise os itens encontrados considerando a solicita√ß√£o do usu√°rio
2. Recomende os 3 MELHORES itens que atendem √† necessidade
3. Para cada recomenda√ß√£o, explique BREVEMENTE por que √© adequada
4. Se houver diferen√ßas importantes entre os itens, destaque-as
5. Se nenhum item for realmente adequado, mencione isso

FORMATO DA RESPOSTA:
üéØ RECOMENDA√á√ïES PARA: [solicita√ß√£o]

ü•á PRIMEIRA OP√á√ÉO
C√≥digo: [c√≥digo]
Por que: [justificativa breve]

ü•à SEGUNDA OP√á√ÉO
C√≥digo: [c√≥digo]
Por que: [justificativa breve]

ü•â TERCEIRA OP√á√ÉO
C√≥digo: [c√≥digo]
Por que: [justificativa breve]

üí° OBSERVA√á√ïES IMPORTANTES:
[diferen√ßas relevantes, alertas, ou coment√°rios adicionais]

Seja objetivo e pr√°tico. Foque no que realmente importa para a decis√£o de compra."""
        
        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em compras p√∫blicas e an√°lise do Catmat. Seja objetivo, pr√°tico e focado nas necessidades reais do usu√°rio."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )
            
            ai_time = time.time() - start_time
            logger.info(f"üß† An√°lise IA conclu√≠da em {ai_time:.1f}s")
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Erro na an√°lise IA: {e}")
            return f"‚ùå Erro na an√°lise IA: {e}"